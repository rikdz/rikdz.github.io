---
title: "SemEval 2019 Task 10: Math Question Answering"
authors: "Mark Hopkins, Ronan Le Bras, Cristian Petrescu-Prahova, Gabriel Stanovsky, Hannaneh Hajishirzi, Rik Koncel-Kedziorski"
collection: publications
permalink: /publication/2019-semeval
date: 2019-6-14
venue: 'SemEval 2019'
paperurl: 'http://rikdz.github.io/files/2019-semeval.pdf'
---

Abstract:

We report on the SemEval 2019 task on math question answering. We provided a question set derived from Math SAT practice exams, including 2778 training questions and 1082 test questions. For a significant subset of these questions, we also provided SMT-LIB logical form annotations and an interpreter that could solve these logical forms. Systems were evaluated based on the percentage of correctly answered questions. The top system correctly answered 45% of the test questions, a considerable improvement over the 17% random guessing baseline.

[PDF](http://rikdz.github.io/files/2019-mathqa.pdf)

Bibtex:
{% raw %}
```
@inproceedings{hopkins2019semeval,
  title={Semeval-2019 task 10: Math question answering},
  author={Hopkins, Mark and Le Bras, Ronan and Petrescu-Prahova, Cristian and Stanovsky, Gabriel and Hajishirzi, Hannaneh and Koncel-Kedziorski, Rik},
  booktitle={Proceedings of the 13th International Workshop on Semantic Evaluation},
  pages={893--899},
  year={2019}
}
```
{% endraw %}

